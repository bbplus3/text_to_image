{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2beec7af-51b0-4ae8-87f4-edf2c6ba7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.classes.__path__ = []\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import faiss\n",
    "import networkx as nx\n",
    "import os\n",
    "import gdown\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d73797-3c55-4fe7-bc1e-3460aea4a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bible Data\n",
    "df = pd.read_csv(\"t_bbe.csv\")  # Ensure CSV has a \"text\", \"book\", \"chapter\", and \"verse\" column\n",
    "book_names = {1:'Genesis',2:'Exodus',3:'Leviticus',4:'Numbers',5:'Deuteronomy',6:'Joshua',7:'Judges',8:'Ruth',9:'1 Samuel',10:'2 Samuel',11:'1 Kings',12:'2 Kings',13:'1 Chronicles',14:'2 Chronicles',15:'Ezra',16:'Nehemiah',17:'Esther',18:'Job',19:'Psalms',20:'Proverbs',21:'Ecclesiastes',22:'Song of Solomon',23:'Isaiah',24:'Jeremiah',25:'Lamentations',26:'Ezekiel',27:'Daniel',28:'Hosea',29:'Joel',30:'Amos',31:'Obadiah',32:'Jonah',33:'Micah',34:'Nahum',35:'Habakkuk',36:'Zephaniah',37:'Haggai',38:'Zechariah',39:'Malachi',40:'Matthew',41:'Mark',42:'Luke',43:'John',44:'Acts',45:'Romans',46:'1 Corinthians',47:'2 Corinthians',48:'Galatians',49:'Ephesians',50:'Philippians',51:'Colossians',52:'1 Thessalonians',53:'2 Thessalonians',54:'1 Timothy',55:'2 Timothy',56:'Titus',57:'Philemon',58:'Hebrews',59:'James',60:'1 Peter',61:'2 Peter',62:'1 John',63:'2 John',64:'3 John',65:'Jude',66:'Revelation'}\n",
    "\n",
    "# Map book names to dataframe\n",
    "df['Book Name'] = df['b'].map(book_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24387922-0317-4fb6-ad70-62a3a3e9623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stopwords from NLTK library but remove some to keep positional words in the text for image generation purposes\n",
    "stop_words = ['to', 'any', \"he'd\", \"we've\", 'this', 'have', 'whom', \"isn't\", \"wasn't\", 'own', 'now', 'do', \"mightn't\", 'but', 'yourselves', \"i've\", 'is', \"haven't\", \"he's\", 'your', \"you've\", 'the', \"she'll\", 'did', \"you'll\", 'until', \"wouldn't\", 'than', \"didn't\", 'then', 'with', 'and', \"should've\", 'few', \"it'll\", 'which', 'why', \"we're\", 'should', 'other', \"i'll\", 'an', 'been', \"needn't\", \"hasn't\", 'will', 'only', \"we'll\", \"we'd\", 'what', \"you'd\", \"shouldn't\", 'me', \"i'd\", 'were', \"aren't\", 'so', \"she's\", \"hadn't\", 'o', 'ours', \"they've\", 'very', \"don't\", 'further', 'it', 'by', 'once', 'if', 'doing', 'are', 'no', 'i', 'yours', 'about', \"she'd\", 'most', 'how', \"mustn't\", 'as', 'myself', 'being', 'was', 'or', 'when', \"they're\", \"couldn't\", 'who', 'my', \"doesn't\", 'where', 'yourself', 'for', 'its', \"won't\", 'such', \"he'll\", 'be', 'after', 'these', 'that', \"shan't\", \"they'll\", 'nor', 'they', 'having', 'too', 'himself', 'those', \"i'm\", 'itself', 'just', 'while', 'does', \"that'll\", 'theirs', \"they'd\", 'can', 'of', 'am', 'because', \"it'd\", 'more', 'you', \"weren't\", 'we', 'themselves', 'ourselves', 'a', \"you're\", 'our']\n",
    "df['corpus'] = df['t'].astype(str).str.lower().apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a8794e-eec9-4827-adcc-d6aa8203d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_and_index():\n",
    "    \"\"\"Download and load embeddings and FAISS index.\"\"\"\n",
    "    \n",
    "    # Define file paths\n",
    "    emb_file = \"bible_embeddings.npy\"\n",
    "    index_file = \"bible_faiss.index\"\n",
    "    \n",
    "    # Download embeddings if not present\n",
    "    if not os.path.exists(emb_file):\n",
    "        gdown.download(\"https://drive.google.com/uc?id=1-z5RDrWKn13t65PmsWb4FhOGyRcJbOpB\", emb_file, quiet=False)\n",
    "    \n",
    "    # Download FAISS index if not present\n",
    "    if not os.path.exists(index_file):\n",
    "        gdown.download(\"https://drive.google.com/uc?id=1I7sqgWmMjFcjqDVic73IMPXK8tehcX-A\", index_file, quiet=False)\n",
    "\n",
    "    # Load files\n",
    "    embeddings = np.load(emb_file, allow_pickle=True)\n",
    "    index = faiss.read_index(index_file)\n",
    "\n",
    "    return embeddings, index\n",
    "\n",
    "embeddings, index = load_embeddings_and_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a339db-4e92-45bd-b19d-5a6b7c1cffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(\"bible_embeddings.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91daa69d-bda2-46ec-a0b8-b6a7464869a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(\"bible_faiss.index\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b92ca-e894-4de3-8d23-1ec9a1c18b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentence-BERT model\n",
    "def load_model():\n",
    "    \"\"\"Load Sentence-BERT model.\"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "tokenizer, model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30895ec4-d376-4161-8aec-bb83b767b828",
   "metadata": {},
   "source": [
    "## Create image from words/phrases using BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71127aae-e9f1-432e-b9e4-1283d73138d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_text(embedding, embeddings, df, top_k=1):\n",
    "    \"\"\"Find the most similar verse to a given embedding using cosine similarity.\"\"\"\n",
    "    scores = cosine_similarity(embedding, embeddings)[0]\n",
    "    top_indices = scores.argsort()[-top_k:][::-1]\n",
    "    return df.iloc[top_indices]['t'].values[0]  # Return most relevant verse text\n",
    "\n",
    "# Step 1: Get BERT embedding from input text (already in your code)\n",
    "embedding = get_embedding(\"Your input verse here\")\n",
    "\n",
    "# Step 2: Retrieve the closest verse in the dataset\n",
    "nearest_text = find_nearest_text(embedding, embeddings, df)\n",
    "\n",
    "# Step 3: Generate image using Stable Diffusion\n",
    "generate_image_from_text(nearest_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2624f-8e6e-4b43-ab4a-66314c89a8e7",
   "metadata": {},
   "source": [
    "## Create image from selected bible verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbe76c4-7145-4d21-adce-8757552e1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embedding for a new query\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate embedding for the given text using Sentence-BERT.\"\"\"\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state[:, 0, :].numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "630bb8de-4242-48a6-a1fe-7cec71a70a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A woman clothed with the sun, and the moon under her feet, and upon her head a crown of twelve stars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0bb51d8-b7b8-42c6-8a2a-bf2b5d92127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c408007ad6644be8b40c40fd0b2f199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Stable Diffusion pipeline (text-to-image)\n",
    "def load_image_generator():\n",
    "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id)#, torch_dtype=torch.float16)\n",
    "    #pipe = pipe.to(\"cuda\")  # Ensure CUDA is available\n",
    "    pipe = pipe.to(\"cpu\")\n",
    "    return pipe\n",
    "\n",
    "image_generator = load_image_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d84497e-348e-45a3-9392-7e56a444321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate image from verse text\n",
    "def generate_image_from_text(text, output_path=\"bible_verse_image.png\"):\n",
    "    image = image_generator(text).images[0]\n",
    "    image.save(output_path)\n",
    "    print(f\"Image saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "328a1767-a450-461f-afcf-acc1912c6b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617c384471d04f358e2c03c5c77fb106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to bible_verse_image.png\n"
     ]
    }
   ],
   "source": [
    "generate_image_from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87399706-e18f-455e-b539-aaedfe5f6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"{text}, digital painting, concept art, highly detailed, epic lighting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae7ac975-b3ee-432a-80e5-7781429c1091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884cab78352b472faec1eed9e506c804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "pipe = pipe.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2fd072a-c3f3-4146-aa42-0c162dcf565f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5921f6b643a8489dbe0c7f3d48b2c9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = pipe(prompt).images[0]\n",
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
